{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b72adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a00089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Load and Preprocess Data\n",
    "data = pd.read_csv('NewDataSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a65526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine date and time into one datetime column\n",
    "data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])\n",
    "data = data[data['datetime'].dt.weekday < 5]  # Filter weekdays only\n",
    "data.sort_values('datetime', inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28550c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date and time columns after combining\n",
    "data.drop(columns=['date', 'time'], inplace=True)\n",
    "\n",
    "# Select features\n",
    "features = ['open', 'high', 'low', 'close', 'tick_volume']\n",
    "data_values = data[features].values\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a3c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Create Sequences (e.g., past 60 steps to predict next step)\n",
    "SEQUENCE_LENGTH = 60\n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - SEQUENCE_LENGTH):\n",
    "    X.append(data_scaled[i:i+SEQUENCE_LENGTH])\n",
    "    y.append(data_scaled[i+SEQUENCE_LENGTH])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# STEP 4: Train/Test Split (time-based)\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6cbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Define Attention Layer\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        scores = K.softmax(K.sum(inputs, axis=-1, keepdims=True), axis=1)\n",
    "        context = inputs * scores\n",
    "        return K.sum(context, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e353ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m5\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m68,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention (\u001b[38;5;33mAttention\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,501</span> (478.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m122,501\u001b[0m (478.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,501</span> (478.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,501\u001b[0m (478.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STEP 6: Build LSTM + Attention Model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = LSTM(128, return_sequences=True)(inputs)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Attention()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(5)(x)  # Predict open, high, low, close, volume\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1af3c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 86ms/step - loss: 0.0021 - val_loss: 2.8393e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 95ms/step - loss: 7.8699e-04 - val_loss: 2.1454e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 75ms/step - loss: 6.2671e-04 - val_loss: 1.3135e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 73ms/step - loss: 4.9964e-04 - val_loss: 1.2850e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 76ms/step - loss: 4.5181e-04 - val_loss: 7.7583e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 81ms/step - loss: 3.3672e-04 - val_loss: 9.5489e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 76ms/step - loss: 3.0823e-04 - val_loss: 7.3958e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 76ms/step - loss: 3.0615e-04 - val_loss: 5.0722e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 86ms/step - loss: 2.9776e-04 - val_loss: 6.2308e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 78ms/step - loss: 2.8710e-04 - val_loss: 4.3836e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 80ms/step - loss: 2.9165e-04 - val_loss: 5.0167e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 94ms/step - loss: 2.8199e-04 - val_loss: 5.4284e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 87ms/step - loss: 2.8491e-04 - val_loss: 7.7427e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 83ms/step - loss: 2.8516e-04 - val_loss: 5.2637e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 81ms/step - loss: 2.8748e-04 - val_loss: 5.9831e-05\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Train Model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e729d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m544/544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 29ms/step - loss: 1.5233e-04\n",
      "Test MSE Loss: 0.00028687555459327996\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: Evaluate Model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test MSE Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "221f7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9: Recursive Future Forecast Function\n",
    "def recursive_forecast(model, data_scaled, scaler, sequence_length, future_steps):\n",
    "    input_seq = data_scaled[-sequence_length:].reshape(1, sequence_length, data_scaled.shape[1])\n",
    "    predictions_scaled = []\n",
    "\n",
    "    for _ in range(future_steps):\n",
    "        pred = model.predict(input_seq)\n",
    "        predictions_scaled.append(pred[0])\n",
    "        # Update input sequence\n",
    "        input_seq = np.append(input_seq[:, 1:, :], [[pred[0]]], axis=1)\n",
    "\n",
    "    predictions_scaled = np.array(predictions_scaled)\n",
    "    predictions_actual = scaler.inverse_transform(predictions_scaled)\n",
    "    return predictions_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08ed7b92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# STEP 10: Predict Future and Plot\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m future_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter number of future 30-min steps to predict: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m recursive_forecast(model, data_scaled, scaler, SEQUENCE_LENGTH, future_steps)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Generate future timestamps\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# STEP 10: Predict Future and Plot\n",
    "future_steps = int(input(\"Enter number of future 30-min steps to predict: \"))\n",
    "predictions = recursive_forecast(model, data_scaled, scaler, SEQUENCE_LENGTH, future_steps)\n",
    "\n",
    "# Generate future timestamps\n",
    "last_datetime = data['datetime'].iloc[-1]\n",
    "future_datetimes = [last_datetime + timedelta(minutes=30 * i) for i in range(1, future_steps + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "pred_df = pd.DataFrame(predictions, columns=features)\n",
    "pred_df['datetime'] = future_datetimes\n",
    "\n",
    "# Plot each feature\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(data['datetime'].iloc[-100:], data[feature].iloc[-100:], label='Actual')\n",
    "    plt.plot(pred_df['datetime'], pred_df[feature], label='Forecast')\n",
    "    plt.title(f\"{feature.capitalize()} Prediction\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(feature)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Plot training loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
