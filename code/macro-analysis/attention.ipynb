{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e73f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e6826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Load and Preprocess Data\n",
    "data = pd.read_csv('NewDataSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abfbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine date and time into one datetime column\n",
    "data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])\n",
    "data = data[data['datetime'].dt.weekday < 5]  # Filter weekdays only\n",
    "data.sort_values('datetime', inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0315f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date and time columns after combining\n",
    "data.drop(columns=['date', 'time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9c1df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "features = ['open', 'high', 'low', 'close', 'tick_volume']\n",
    "data_values = data[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba1d3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b751d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Create Sequences (e.g., past 60 steps to predict next step)\n",
    "SEQUENCE_LENGTH = 60\n",
    "X, y, timestamps = [], [], []\n",
    "for i in range(len(data_scaled) - SEQUENCE_LENGTH):\n",
    "    X.append(data_scaled[i:i+SEQUENCE_LENGTH])\n",
    "    y.append(data_scaled[i+SEQUENCE_LENGTH])\n",
    "    timestamps.append(data['datetime'].iloc[i + SEQUENCE_LENGTH])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "timestamps = np.array(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04c83f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Train/Test Split (time-based)\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "timestamps_test = timestamps[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d15a1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Define Attention Layer\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        scores = K.softmax(K.sum(inputs, axis=-1, keepdims=True), axis=1)\n",
    "        context = inputs * scores\n",
    "        return K.sum(context, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c52c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m5\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m68,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention (\u001b[38;5;33mAttention\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,501</span> (478.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m122,501\u001b[0m (478.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,501</span> (478.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,501\u001b[0m (478.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STEP 6: Build LSTM + Attention Model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = LSTM(128, return_sequences=True)(inputs)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Attention()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(5)(x)  # Predict open, high, low, close, volume\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ae2c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 89ms/step - loss: 0.0020 - val_loss: 3.0090e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 79ms/step - loss: 7.5117e-04 - val_loss: 2.1754e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 77ms/step - loss: 6.0971e-04 - val_loss: 1.3341e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 80ms/step - loss: 5.0855e-04 - val_loss: 1.5540e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 84ms/step - loss: 4.3936e-04 - val_loss: 1.4489e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 93ms/step - loss: 3.6259e-04 - val_loss: 6.7695e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 95ms/step - loss: 3.3182e-04 - val_loss: 6.4593e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 108ms/step - loss: 3.1720e-04 - val_loss: 7.6665e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 103ms/step - loss: 3.0524e-04 - val_loss: 6.1740e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 105ms/step - loss: 3.0331e-04 - val_loss: 4.9277e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 105ms/step - loss: 2.8608e-04 - val_loss: 7.1055e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 104ms/step - loss: 3.0320e-04 - val_loss: 6.1328e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 105ms/step - loss: 2.8679e-04 - val_loss: 4.8745e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 87ms/step - loss: 2.8416e-04 - val_loss: 6.8085e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 80ms/step - loss: 2.7525e-04 - val_loss: 4.8892e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 81ms/step - loss: 2.7955e-04 - val_loss: 7.7874e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 83ms/step - loss: 2.8130e-04 - val_loss: 4.1604e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 80ms/step - loss: 2.7074e-04 - val_loss: 4.7233e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 80ms/step - loss: 2.5579e-04 - val_loss: 4.5326e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 80ms/step - loss: 2.7682e-04 - val_loss: 5.7427e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 80ms/step - loss: 2.6980e-04 - val_loss: 5.2004e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m978/978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 78ms/step - loss: 2.6548e-04 - val_loss: 6.4785e-05\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Train Model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f087b508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m544/544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 1.9045e-04\n",
      "Test MSE Loss: 0.00042429313180036843\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: Evaluate Model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test MSE Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2558118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9: Make Future Prediction Function Based on Date and Time\n",
    "def predict_for_datetime(model, data_scaled, original_data, scaler, sequence_length, target_datetime):\n",
    "    target_datetime = pd.to_datetime(target_datetime)\n",
    "    if target_datetime not in original_data['datetime'].values:\n",
    "        raise ValueError(\"Date and time not found in historical data.\")\n",
    "\n",
    "    idx = original_data.index[original_data['datetime'] == target_datetime][0]\n",
    "    if idx < sequence_length:\n",
    "        raise ValueError(\"Not enough history before the given date and time.\")\n",
    "\n",
    "    input_seq = data_scaled[idx - sequence_length:idx].reshape(1, sequence_length, data_scaled.shape[1])\n",
    "    pred_scaled = model.predict(input_seq)\n",
    "    pred_actual = scaler.inverse_transform(pred_scaled)\n",
    "    return pred_actual[0]  # Return open, high, low, close, tick_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "723fa493",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Date and time not found in historical data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# STEP 10: Predict and Display\u001b[39;00m\n\u001b[0;32m      2\u001b[0m user_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the datetime for prediction (YYYY-MM-DD HH:MM:SS): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_for_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSEQUENCE_LENGTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_datetime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Values for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (open, high, low, close, tick_volume):\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(user_datetime))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m, in \u001b[0;36mpredict_for_datetime\u001b[1;34m(model, data_scaled, original_data, scaler, sequence_length, target_datetime)\u001b[0m\n\u001b[0;32m      3\u001b[0m target_datetime \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(target_datetime)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_datetime \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m original_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate and time not found in historical data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m idx \u001b[38;5;241m=\u001b[39m original_data\u001b[38;5;241m.\u001b[39mindex[original_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m target_datetime][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m sequence_length:\n",
      "\u001b[1;31mValueError\u001b[0m: Date and time not found in historical data."
     ]
    }
   ],
   "source": [
    "# STEP 10: Predict and Display\n",
    "user_datetime = input(\"Enter the datetime for prediction (YYYY-MM-DD HH:MM:SS): \")\n",
    "prediction = predict_for_datetime(model, data_scaled, data, scaler, SEQUENCE_LENGTH, user_datetime)\n",
    "print(\"Predicted Values for {} (open, high, low, close, tick_volume):\".format(user_datetime))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Plot training loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
